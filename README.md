# Adapta√ß√µes do Notebook CNN - De C√£es e Gatos para Tumores Cerebrais

Este documento descreve as adapta√ß√µes realizadas para transformar o notebook `cnn_caes_gatos.ipynb` (classifica√ß√£o de c√£es e gatos) no notebook `cnn_brain_tumor.ipynb` (classifica√ß√£o de tumores cerebrais em imagens de MRI).

---

## üìã Resumo das Mudan√ßas

| Aspecto | C√£es e Gatos | Tumores Cerebrais |
|---------|--------------|-------------------|
| **Classes** | 2 (dog, cat) | 4 (glioma, meningioma, notumor, pituitary) |
| **Tamanho das imagens** | 100x100 | 150x150 |
| **Carregamento de dados** | Manual (listdir + load_img) | `keras.utils.image_dataset_from_directory()` |
| **Data Augmentation** | N√£o utilizado | Sim (camadas Keras: RandomRotation, RandomZoom, etc.) |
| **Arquitetura CNN** | N√£o definida no notebook | 5 camadas convolucionais + BatchNorm + Dropout |
| **Callbacks** | N√£o utilizados | EarlyStopping, ModelCheckpoint, ReduceLROnPlateau |
| **M√©tricas** | B√°sicas | Matriz de confus√£o, relat√≥rio de classifica√ß√£o |
| **APIs Keras** | Legado (`tensorflow.keras`) | Moderno (`keras` 3.x + `tf.data`) |

---

## üîÑ Adapta√ß√µes Detalhadas

### 1. **Estrutura do Dataset**

**Antes (C√£es e Gatos):**
```
imgsdogsandcats/
‚îú‚îÄ‚îÄ dogs/
‚îî‚îÄ‚îÄ cats/
```

**Depois (Tumores Cerebrais):**
```
Brain Tumor MRI Dataset/
‚îú‚îÄ‚îÄ Training/
‚îÇ   ‚îú‚îÄ‚îÄ glioma/
‚îÇ   ‚îú‚îÄ‚îÄ meningioma/
‚îÇ   ‚îú‚îÄ‚îÄ notumor/
‚îÇ   ‚îî‚îÄ‚îÄ pituitary/
‚îî‚îÄ‚îÄ Testing/
    ‚îú‚îÄ‚îÄ glioma/
    ‚îú‚îÄ‚îÄ meningioma/
    ‚îú‚îÄ‚îÄ notumor/
    ‚îî‚îÄ‚îÄ pituitary/
```

**Justificativa:** O dataset de tumores cerebrais possui uma estrutura mais organizada com separa√ß√£o expl√≠cita entre treino e teste, al√©m de 4 classes em vez de 2.

---

### 2. **Carregamento de Dados**

**Antes:**
- Carregamento manual usando `os.listdir()` e `keras.utils.load_img()`
- Salvamento em arquivos `.pkl` e `.csv`
- Processamento manual de strings para converter dados

**Depois:**
- Uso do `keras.utils.image_dataset_from_directory()` (API moderna)
- Pipeline `tf.data` para carregamento eficiente
- Otimiza√ß√£o com `cache()`, `shuffle()` e `prefetch()`
- Split autom√°tico treino/valida√ß√£o (80/20)

```python
# Novo m√©todo de carregamento (API moderna)
train_dataset = keras.utils.image_dataset_from_directory(
    train_dir,
    image_size=IMG_SIZE,
    batch_size=BATCH_SIZE,
    validation_split=0.2,
    subset="training",
    seed=42,
    label_mode='categorical',
    shuffle=True
)

# Otimiza√ß√£o com tf.data
AUTOTUNE = tf.data.AUTOTUNE
train_dataset = train_dataset.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)
```

**Justificativa:** 
- `image_dataset_from_directory()` √© a API recomendada no Keras 3.x
- `tf.data` oferece melhor performance e gerenciamento de mem√≥ria
- `ImageDataGenerator` est√° depreciado

---

### 3. **Data Augmentation**

**Antes:** N√£o utilizado

**Depois:** Implementado com camadas Keras (API moderna):
```python
# Camadas de augmentation integradas ao modelo
data_augmentation = keras.Sequential([
    layers.RandomRotation(0.1),           # Rota√ß√£o aleat√≥ria (¬±10% de 360¬∞)
    layers.RandomTranslation(0.2, 0.2),   # Deslocamento horizontal e vertical
    layers.RandomZoom(0.2),               # Zoom aleat√≥rio
    layers.RandomFlip("horizontal"),      # Flip horizontal
], name="data_augmentation")
```

**Justificativa:** 
- As camadas de augmentation s√£o aplicadas automaticamente apenas durante o treinamento
- Integra√ß√£o nativa com o modelo Keras
- Substituem o depreciado `ImageDataGenerator`
- Melhor performance com GPU

---

### 4. **Arquitetura do Modelo CNN**

**Antes:** O notebook original n√£o define explicitamente a arquitetura CNN (foca apenas no carregamento de dados)

**Depois:** CNN completa com 5 blocos convolucionais usando API Funcional:

```python
# Modelo usando API Funcional do Keras (moderno)
inputs = keras.Input(shape=input_shape)

# Data augmentation integrado ao modelo
x = data_augmentation(inputs)

# Bloco 1: 32 filtros
x = layers.Conv2D(32, (3, 3), activation='relu')(x)
x = layers.BatchNormalization()(x)
x = layers.MaxPooling2D((2, 2))(x)

# ... (blocos 2-5 com 64, 128, 256, 512 filtros)

# Camadas densas com Dropout
x = layers.Flatten()(x)
x = layers.Dense(512, activation='relu')(x)
x = layers.Dropout(0.5)(x)
x = layers.Dense(256, activation='relu')(x)
x = layers.Dropout(0.3)(x)

# Camada de sa√≠da
outputs = layers.Dense(num_classes, activation='softmax')(x)

model = keras.Model(inputs, outputs)
```

**Justificativa:** 
- **API Funcional:** Permite integrar data augmentation diretamente no modelo
- **BatchNormalization:** Estabiliza e acelera o treinamento
- **Dropout:** Previne overfitting nas camadas densas
- **Softmax:** Apropriado para classifica√ß√£o multiclasse (4 classes)

---

### 5. **Fun√ß√£o de Perda e M√©tricas**

**Antes:** Classifica√ß√£o bin√°ria (2 classes - dog/cat)

**Depois:** Classifica√ß√£o multiclasse (4 classes)
```python
model.compile(
    optimizer=keras.optimizers.Adam(learning_rate=0.001),
    loss='categorical_crossentropy',  # Para multiclasse
    metrics=['accuracy']
)
```

**Justificativa:** `categorical_crossentropy` √© a fun√ß√£o de perda adequada para problemas de classifica√ß√£o multiclasse com labels one-hot encoded.

---

### 6. **Callbacks de Treinamento**

**Antes:** N√£o utilizados

**Depois:** Tr√™s callbacks importantes:

```python
callbacks = [
    EarlyStopping(
        monitor='val_loss',
        patience=10,
        restore_best_weights=True
    ),
    ModelCheckpoint(
        'best_brain_tumor_model.keras',
        monitor='val_accuracy',
        save_best_only=True
    ),
    ReduceLROnPlateau(
        monitor='val_loss',
        factor=0.2,
        patience=5,
        min_lr=1e-7
    )
]
```

**Justificativa:**
- **EarlyStopping:** Para o treinamento quando n√£o h√° melhora, evitando overfitting
- **ModelCheckpoint:** Salva o melhor modelo durante o treinamento
- **ReduceLROnPlateau:** Reduz a taxa de aprendizado quando o modelo estagna

---

### 7. **Avalia√ß√£o e M√©tricas**

**Antes:** Apenas visualiza√ß√£o b√°sica das imagens

**Depois:** Avalia√ß√£o completa com:
- Matriz de confus√£o com visualiza√ß√£o heatmap
- Relat√≥rio de classifica√ß√£o (precision, recall, F1-score)
- M√©tricas por classe (acur√°cia, precis√£o, recall, F1)
- Visualiza√ß√£o de predi√ß√µes com confian√ßa

```python
# Relat√≥rio de classifica√ß√£o
print(classification_report(true_classes, predicted_classes, target_names=target_names))

# Matriz de confus√£o
cm = confusion_matrix(true_classes, predicted_classes)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
```

**Justificativa:** Em aplica√ß√µes m√©dicas, √© crucial entender n√£o apenas a acur√°cia geral, mas tamb√©m o desempenho por classe e os tipos de erros cometidos.

---

### 8. **Fun√ß√£o de Predi√ß√£o Individual**

**Antes:** N√£o dispon√≠vel

**Depois:** Fun√ß√£o para classificar uma √∫nica imagem:
```python
def predict_single_image(model, image_path, img_size=(150, 150)):
    # Carrega, preprocessa e prediz uma imagem
    # Retorna a classe predita e a confian√ßa
    # Exibe probabilidades para cada classe
```

**Justificativa:** √ötil para uso pr√°tico do modelo em produ√ß√£o ou para testar imagens individuais.

---

### 9. **Salvamento do Modelo**

**Antes:** Dados salvos em arquivos `.pkl` e `.csv`

**Depois:** Modelo salvo apenas no formato moderno `.keras`:
```python
model.save('brain_tumor_classifier_final.keras')  # Formato nativo Keras 3.x
```

**Justificativa:** 
- O formato `.keras` √© o padr√£o recomendado no Keras 3.x
- O formato `.h5` est√° depreciado e pode ter problemas de compatibilidade
- Melhor suporte para camadas customizadas e configura√ß√µes complexas

---

## üîÑ Atualiza√ß√£o para APIs Modernas do Keras

O notebook foi atualizado para usar as APIs mais recentes do Keras 3.x, removendo depend√™ncias legadas:

### Mudan√ßas nas Importa√ß√µes

**Antes (Legado):**
```python
from tensorflow.keras import layers, models
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.preprocessing.image import load_img, img_to_array
```

**Depois (Moderno):**
```python
import keras
from keras import layers, models
from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
```

### Mudan√ßas no Carregamento de Imagens

**Antes (Depreciado):**
```python
from tensorflow.keras.preprocessing.image import load_img, img_to_array
img = load_img(path, target_size=(150, 150))
```

**Depois (Moderno):**
```python
img = keras.utils.load_img(path, target_size=(150, 150))
img_array = keras.utils.img_to_array(img)
```

### Mudan√ßas no Data Augmentation

**Antes (Depreciado):**
```python
train_datagen = ImageDataGenerator(
    rotation_range=20,
    width_shift_range=0.2,
    ...
)
train_generator = train_datagen.flow_from_directory(...)
```

**Depois (Moderno):**
```python
# Camadas de augmentation
data_augmentation = keras.Sequential([
    layers.RandomRotation(0.1),
    layers.RandomTranslation(0.2, 0.2),
    layers.RandomZoom(0.2),
    layers.RandomFlip("horizontal"),
])

# Carregamento com tf.data
train_dataset = keras.utils.image_dataset_from_directory(...)
train_dataset = train_dataset.cache().prefetch(buffer_size=AUTOTUNE)
```

### Resumo das APIs Atualizadas

| Fun√ß√£o Legada | Fun√ß√£o Moderna |
|---------------|----------------|
| `tensorflow.keras.*` | `keras.*` |
| `ImageDataGenerator` | `keras.utils.image_dataset_from_directory()` + `tf.data` |
| `flow_from_directory()` | `keras.utils.image_dataset_from_directory()` |
| `load_img()` | `keras.utils.load_img()` |
| `img_to_array()` | `keras.utils.img_to_array()` |
| `model.save('file.h5')` | `model.save('file.keras')` |

---

## üìä Comparativo de Complexidade

| Caracter√≠stica | C√£es e Gatos | Tumores Cerebrais |
|----------------|--------------|-------------------|
| N√∫mero de classes | 2 | 4 |
| Complexidade do problema | Baixa | Alta |
| Import√¢ncia de erros | Baixa | Alta (aplica√ß√£o m√©dica) |
| Necessidade de m√©tricas | B√°sica | Detalhada |
| Regulariza√ß√£o | M√≠nima | Extensiva (Dropout, BatchNorm) |

---

## üéØ Conclus√£o

As principais adapta√ß√µes foram necess√°rias para:

1. **Lidar com mais classes:** De 2 para 4 classes, exigindo mudan√ßa na camada de sa√≠da e fun√ß√£o de perda
2. **Melhorar generaliza√ß√£o:** Data augmentation e regulariza√ß√£o para evitar overfitting
3. **Avalia√ß√£o mais rigorosa:** M√©tricas detalhadas essenciais para aplica√ß√µes m√©dicas
4. **Efici√™ncia no carregamento:** `tf.data` e `image_dataset_from_directory()` para datasets maiores
5. **Monitoramento do treinamento:** Callbacks para otimizar o processo de treinamento
6. **Atualiza√ß√£o para APIs modernas:** Uso do Keras 3.x com `tf.data` em vez de APIs depreciadas

O notebook de tumores cerebrais representa uma evolu√ß√£o significativa em termos de boas pr√°ticas de deep learning, adequa√ß√£o para um problema real de diagn√≥stico m√©dico e uso de APIs modernas e recomendadas do Keras/TensorFlow.

---

## üñ•Ô∏è Adapta√ß√£o para VS Code (Execu√ß√£o Local)

O notebook foi adaptado para permitir execu√ß√£o tanto no Google Colab quanto localmente no VS Code. As seguintes mudan√ßas foram realizadas:

### C√©lula 1 - C√≥digo do Colab Comentado

O c√≥digo espec√≠fico do Google Colab foi comentado e substitu√≠do por uma detec√ß√£o de ambiente:

```python
# ============================================================
# C√ìDIGO DO GOOGLE COLAB (COMENTADO)
# Descomente as linhas abaixo se estiver rodando no Google Colab
# ============================================================
# from google.colab import drive
# drive.mount('/content/drive')

# Detec√ß√£o autom√°tica do ambiente (VS Code local)
IN_COLAB = False
print(f"Ambiente: {'Google Colab' if IN_COLAB else 'VS Code Local'}")
```

### C√©lula 3 - Configura√ß√£o do Ambiente

O bloco de montagem do Google Drive e mudan√ßa de diret√≥rio foi comentado:

```python
# ============================================================
# C√ìDIGO DO GOOGLE COLAB (COMENTADO)
# Descomente o bloco abaixo se estiver rodando no Google Colab
# ============================================================
# if IN_COLAB:
#     from google.colab import drive
#     drive.mount("/content/drive")
#     os.chdir("/content/drive/My Drive/Colab Notebooks/trabalho_final")

# Para VS Code: n√£o √© necess√°rio mudar diret√≥rio
print(f"Rodando no ambiente: {'Google Colab' if IN_COLAB else 'VS Code Local'}")
print(f"Diret√≥rio atual: {os.getcwd()}")
```

### C√©lula 4 - Caminhos dos Diret√≥rios (Simplificado)

Removidos os condicionais `if IN_COLAB` e usado `os.path.join()` para compatibilidade:

```python
# Usando os.path.join para compatibilidade entre sistemas operacionais
base_dir = os.path.join(".", "Brain Tumor MRI Dataset")
train_dir = os.path.join(base_dir, "Training")
test_dir = os.path.join(base_dir, "Testing")
```

### C√©lula 5 - Contagem de Imagens (Simplificado)

Removidos os condicionais e padronizado o uso de `os.path.join()`:

```python
for classe in classes:
    path = os.path.join(train_dir, classe)  # Compat√≠vel com qualquer SO
    count = len(os.listdir(path))
```

### Como Executar

**No VS Code (Local):**
1. Certifique-se de que o notebook est√° na pasta `trabalho_final`
2. A pasta `Brain Tumor MRI Dataset` deve estar no mesmo diret√≥rio do notebook
3. Execute as c√©lulas normalmente usando o Jupyter no VS Code
4. Mantenha `IN_COLAB = False` na primeira c√©lula

**No Google Colab:**
1. Altere `IN_COLAB = True` na primeira c√©lula
2. Descomente as linhas de montagem do Google Drive
3. Descomente o bloco de configura√ß√£o de ambiente na c√©lula 3
4. Execute normalmente

### Vantagens da Adapta√ß√£o

| Aspecto | Google Colab | VS Code Local |
|---------|--------------|---------------|
| **GPU** | Gratuita (limitada) | Depende do hardware |
| **Armazenamento** | Google Drive | Disco local |
| **Velocidade I/O** | Mais lento (rede) | Mais r√°pido (local) |
| **Sess√£o** | Expira ap√≥s inatividade | Persistente |
| **Debugging** | Limitado | Completo |

---

## üîß Revis√£o de C√≥digo e Corre√ß√µes

O notebook passou por uma revis√£o completa para identificar problemas e aplicar melhorias. Abaixo est√£o documentadas todas as corre√ß√µes realizadas:

### ‚ùå Problemas Identificados e Corrigidos

#### 1. **Ordem das C√©lulas Incorreta**

**Problema:** A c√©lula de carregamento do modelo salvo estava no final do notebook (ap√≥s o treinamento e avalia√ß√£o), quando deveria estar ANTES da c√©lula de treinamento.

**Corre√ß√£o:** A c√©lula foi movida para logo ap√≥s a compila√ß√£o do modelo, permitindo que o fluxo de execu√ß√£o detecte se existe um modelo salvo antes de decidir treinar.

**Localiza√ß√£o:** Nova posi√ß√£o ap√≥s a c√©lula "Compilar o modelo"

---

#### 2. **Vari√°vel `TREINAR` N√£o Definida**

**Problema:** A vari√°vel `TREINAR` era usada na c√©lula de treinamento, mas s√≥ era definida na c√©lula de carregamento do modelo (que estava fora de ordem). Isso causaria erro `NameError: name 'TREINAR' is not defined`.

**Corre√ß√£o:** A c√©lula de verifica√ß√£o do modelo salvo agora est√° posicionada corretamente e define `TREINAR = True` ou `TREINAR = False` baseado na exist√™ncia do arquivo.

```python
if os.path.exists(modelo_salvo):
    model = keras.models.load_model(modelo_salvo)
    TREINAR = False
else:
    TREINAR = True
```

---

#### 3. **Erro ao Plotar Hist√≥rico sem Treinar**

**Problema:** Se o modelo fosse carregado de arquivo (sem treinar), a vari√°vel `history` n√£o existiria, causando erro ao tentar plotar o hist√≥rico de treinamento.

**Corre√ß√£o:** Adicionada verifica√ß√£o condicional:

```python
if TREINAR and 'history' in dir():
    plot_training_history(history)
else:
    print("‚ÑπÔ∏è Hist√≥rico de treinamento n√£o dispon√≠vel (modelo carregado de arquivo).")
```

---

#### 4. **Import Duplicado**

**Problema:** O m√≥dulo `os` era importado novamente na c√©lula de carregamento do modelo, sendo desnecess√°rio pois j√° havia sido importado anteriormente.

**Corre√ß√£o:** Removido o import duplicado.

---

#### 5. **Fun√ß√£o `predict_single_image` Melhorada**

**Problemas:**
- N√£o verificava se o arquivo de imagem existia
- Usava lista hardcoded de classes em vez da vari√°vel `class_names`
- Caminho hardcoded para imagem de teste

**Corre√ß√µes:**
```python
def predict_single_image(model, image_path, img_size=(150, 150)):
    # Verificar se o arquivo existe
    if not os.path.exists(image_path):
        print(f"‚ùå Erro: Arquivo n√£o encontrado: {image_path}")
        return None, None
    
    # Usar class_names se dispon√≠vel
    class_labels = class_names if 'class_names' in dir() else ['glioma', 'meningioma', 'notumor', 'pituitary']
    
    # ... resto do c√≥digo
```

---

### ‚úÖ Melhorias Aplicadas

#### 1. **Feedback Visual Aprimorado**

Adicionados emojis e mensagens mais claras para indicar o status:

```python
print(f"‚úÖ Modelo salvo encontrado: {modelo_salvo}")
print(f"‚ö†Ô∏è Modelo n√£o encontrado: {modelo_salvo}")
print("‚ÑπÔ∏è Hist√≥rico de treinamento n√£o dispon√≠vel")
```

---

#### 2. **Fluxo de Execu√ß√£o Otimizado**

O notebook agora segue a ordem correta:

1. Configura√ß√£o do ambiente
2. Carregamento dos dados
3. Cria√ß√£o e compila√ß√£o do modelo
4. **Verifica√ß√£o de modelo salvo** ‚Üê Nova posi√ß√£o
5. Treinamento (se necess√°rio)
6. Avalia√ß√£o
7. Salvamento

---

#### 3. **Exemplo de Uso Din√¢mico**

A fun√ß√£o `predict_single_image` agora tem um exemplo que usa o pr√≥prio dataset:

```python
# Para testar com uma imagem do dataset:
exemplo_imagem = os.path.join(test_dir, "glioma", os.listdir(os.path.join(test_dir, "glioma"))[0])
predicted_class, confidence = predict_single_image(model, exemplo_imagem)
```

---

### üìã Checklist de Qualidade

| Item | Status |
|------|--------|
| Ordem das c√©lulas correta | ‚úÖ |
| Vari√°veis definidas antes do uso | ‚úÖ |
| Tratamento de erros | ‚úÖ |
| Imports sem duplica√ß√£o | ‚úÖ |
| Compatibilidade Windows/Linux | ‚úÖ |
| Feedback ao usu√°rio | ‚úÖ |
| C√≥digo documentado | ‚úÖ |
| APIs modernas do Keras | ‚úÖ |

---

## üìö Refer√™ncias

- [Keras 3.x Documentation](https://keras.io/)
- [TensorFlow Data API](https://www.tensorflow.org/guide/data)
- [Image Classification Tutorial](https://www.tensorflow.org/tutorials/images/classification)
- [Data Augmentation Layers](https://keras.io/api/layers/preprocessing_layers/image_augmentation/)
- [Jupyter in VS Code](https://code.visualstudio.com/docs/datascience/jupyter-notebooks)
